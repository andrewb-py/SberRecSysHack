{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9986528,"sourceType":"datasetVersion","datasetId":6145802},{"sourceId":9995070,"sourceType":"datasetVersion","datasetId":6151778},{"sourceId":9995167,"sourceType":"datasetVersion","datasetId":6151837}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install implicit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:46:57.024235Z","iopub.execute_input":"2024-11-23T14:46:57.024523Z","iopub.status.idle":"2024-11-23T14:47:07.077771Z","shell.execute_reply.started":"2024-11-23T14:46:57.024496Z","shell.execute_reply":"2024-11-23T14:47:07.076705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport pyarrow.parquet as pq\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom catboost import CatBoostRanker, Pool\nfrom scipy.sparse import csr_matrix\nfrom implicit.als import AlternatingLeastSquares\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nfrom transformers import BertConfig, BertForMaskedLM, AdamW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:09.970845Z","iopub.execute_input":"2024-11-23T14:47:09.971565Z","iopub.status.idle":"2024-11-23T14:47:15.904974Z","shell.execute_reply.started":"2024-11-23T14:47:09.971527Z","shell.execute_reply":"2024-11-23T14:47:15.904125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Константы\nK = 10  # Кол-во рекомендаций\n# DATA_PATH = '.'  # Текущая директория\nDATA_PATH = \"/kaggle/working/\"\nINPUT_PATH = \"/kaggle/input/sber-recsys-hack\"\n\nMODEL_PATH = os.path.join(DATA_PATH, 'models')\nos.makedirs(MODEL_PATH, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:15.906774Z","iopub.execute_input":"2024-11-23T14:47:15.907675Z","iopub.status.idle":"2024-11-23T14:47:15.912720Z","shell.execute_reply.started":"2024-11-23T14:47:15.907629Z","shell.execute_reply":"2024-11-23T14:47:15.911496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Использование GPU, если доступно\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:15.913598Z","iopub.execute_input":"2024-11-23T14:47:15.913832Z","iopub.status.idle":"2024-11-23T14:47:15.962515Z","shell.execute_reply.started":"2024-11-23T14:47:15.913809Z","shell.execute_reply":"2024-11-23T14:47:15.961692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Генерация кандидатов с ALS\ndef generate_candidates_als(train, user_encoder, item_encoder):\n    user_item_matrix = csr_matrix(\n        (train['rating'], (train['user_id_enc'], train['item_id_enc']))\n    )\n    als_model = AlternatingLeastSquares(\n        factors=64,\n        regularization=0.1,\n        iterations=15,\n    )\n    als_model.fit(user_item_matrix.T)\n    return als_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:15.964536Z","iopub.execute_input":"2024-11-23T14:47:15.964830Z","iopub.status.idle":"2024-11-23T14:47:15.973048Z","shell.execute_reply.started":"2024-11-23T14:47:15.964805Z","shell.execute_reply":"2024-11-23T14:47:15.972333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Датасет для BERT4Rec\nclass BERT4RecDataset(Dataset):\n    def __init__(self, sequences, item_num, max_seq_length=50, mask_prob=0.15):\n        self.sequences = sequences\n        self.max_seq_length = max_seq_length\n        self.mask_prob = mask_prob\n        self.item_num = item_num\n        self.special_tokens = {\n            'pad': 0,\n            'mask': item_num + 1\n        }\n        self.vocab_size = item_num + 2\n\n    def __len__(self):\n        return len(self.sequences)\n\n    def __getitem__(self, idx):\n        seq = self.sequences[idx][-self.max_seq_length:]\n        tokens = seq + [self.special_tokens['pad']] * (self.max_seq_length - len(seq))\n        tokens = torch.tensor(tokens, dtype=torch.long)\n\n        input_ids = tokens.clone()\n        labels = tokens.clone()\n\n        probability_matrix = torch.full(labels.shape, self.mask_prob)\n        masked_indices = torch.bernoulli(probability_matrix).bool() & (tokens != self.special_tokens['pad'])\n        labels[~masked_indices] = -100\n\n        input_ids[masked_indices] = self.special_tokens['mask']\n\n        return input_ids, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:15.973886Z","iopub.execute_input":"2024-11-23T14:47:15.974221Z","iopub.status.idle":"2024-11-23T14:47:15.983602Z","shell.execute_reply.started":"2024-11-23T14:47:15.974197Z","shell.execute_reply":"2024-11-23T14:47:15.982929Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучение BERT4Rec\ndef train_bert4rec(train_sequences, item_num, max_seq_length=50, epochs=3, batch_size=50):\n    dataset = BERT4RecDataset(train_sequences, item_num, max_seq_length)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n    # Конфигурация BERT4Rec\n    config = BertConfig(\n        vocab_size=dataset.vocab_size,\n        max_position_embeddings=max_seq_length,\n        hidden_size=256,\n        num_hidden_layers=2,\n        num_attention_heads=4,\n        intermediate_size=512,\n        hidden_dropout_prob=0.1,\n        attention_probs_dropout_prob=0.1\n    )\n\n    model = BertForMaskedLM(config)\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(epochs):\n        epoch_loss = 0\n        for input_ids, labels in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\"):\n            input_ids = input_ids.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids=input_ids, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            epoch_loss += loss.item()\n        print(f'Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(dataloader)}')\n    return model, dataset.special_tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:15.984517Z","iopub.execute_input":"2024-11-23T14:47:15.984726Z","iopub.status.idle":"2024-11-23T14:47:15.998329Z","shell.execute_reply.started":"2024-11-23T14:47:15.984705Z","shell.execute_reply":"2024-11-23T14:47:15.997476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CatBoost как ранжирующая модель\ndef train_ranking_model(train_df, user_features, item_features):\n    X_train = train_df.merge(user_features, on='user_id').merge(item_features, on='item_id')\n    y_train = X_train['rating']\n    group_id = X_train['user_id']\n    cat_features = ['domain', 'day_of_week', 'hour_of_day']\n    X_train = X_train.drop(['user_id', 'item_id', 'rating'], axis=1)\n    print(X_train.head(1))\n\n    # Для правильного кодирования категориальных признаков\n    for col in cat_features:\n        X_train[col] = X_train[col].astype(str)\n\n    train_pool = Pool(\n        data=X_train,\n        label=y_train,\n        group_id=group_id,\n        cat_features=cat_features\n    )\n    model = CatBoostRanker(\n        iterations=100,\n        depth=6,\n        learning_rate=0.1,\n        task_type='GPU',\n        verbose=10\n    )\n    model.fit(train_pool)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:26:14.406716Z","iopub.execute_input":"2024-11-23T16:26:14.407061Z","iopub.status.idle":"2024-11-23T16:26:14.413020Z","shell.execute_reply.started":"2024-11-23T16:26:14.407033Z","shell.execute_reply":"2024-11-23T16:26:14.412177Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Препроцессинг\ndef preprocess_data(train, test):\n    # Для послеующего объединения и корректного разбиения\n    train['is_test'] = 0\n    test['is_test'] = 1\n\n    # Комбинирование трейна и теста для совместного препроцессинга\n    combined = pd.concat([train, test], ignore_index=True)\n\n    # Заполнение пропущенных значений (просто на всякий случай)\n    combined.fillna(0, inplace=True)\n\n    # Конвертирование datetime в привычный формат\n    combined['datetime'] = pd.to_datetime(combined['timestamp'])\n\n    # Генерация временных признаков\n    combined['day_of_week'] = combined['datetime'].dt.dayofweek\n    combined['hour_of_day'] = combined['datetime'].dt.hour\n\n    # Отбрасывание изначальной колонки\n    combined.drop('timestamp', axis=1, inplace=True)\n\n    # Обратное разбиение на трейн и тест\n    train = combined[combined['is_test'] == 0].drop(columns=['is_test'])\n    test = combined[combined['is_test'] == 1].drop(columns=['is_test'])\n\n    return train, test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:16.014316Z","iopub.execute_input":"2024-11-23T14:47:16.014530Z","iopub.status.idle":"2024-11-23T14:47:16.027962Z","shell.execute_reply.started":"2024-11-23T14:47:16.014509Z","shell.execute_reply":"2024-11-23T14:47:16.027029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Загрузка данных для обоих доменов\ntrain_zvuk = pq.read_table(os.path.join(INPUT_PATH, 'train_zvuk.parquet')).to_pandas()\ntest_zvuk = pq.read_table(os.path.join(INPUT_PATH, 'test_zvuk.parquet')).to_pandas()\ntrain_smm = pq.read_table(os.path.join(INPUT_PATH, 'train_smm.parquet')).to_pandas()\ntest_smm = pq.read_table(os.path.join(INPUT_PATH, 'test_smm.parquet')).to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:16.029056Z","iopub.execute_input":"2024-11-23T14:47:16.029373Z","iopub.status.idle":"2024-11-23T14:47:25.944014Z","shell.execute_reply.started":"2024-11-23T14:47:16.029347Z","shell.execute_reply":"2024-11-23T14:47:25.943316Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Добавление индикаторов доменов\ntrain_zvuk['domain'] = 'zvuk'\ntest_zvuk['domain'] = 'zvuk'\ntrain_smm['domain'] = 'smm'\ntest_smm['domain'] = 'smm'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:25.947526Z","iopub.execute_input":"2024-11-23T14:47:25.947786Z","iopub.status.idle":"2024-11-23T14:47:26.697196Z","shell.execute_reply.started":"2024-11-23T14:47:25.947763Z","shell.execute_reply":"2024-11-23T14:47:26.696266Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Сдвиг значений id для айтемов МегаМаркета, чтобы не повторялись со Звуком\nmax_item_id_zvuk = train_zvuk['item_id'].max()\ntrain_smm['item_id'] += max_item_id_zvuk + 1\ntest_smm['item_id'] += max_item_id_zvuk + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:26.698437Z","iopub.execute_input":"2024-11-23T14:47:26.699196Z","iopub.status.idle":"2024-11-23T14:47:26.947710Z","shell.execute_reply.started":"2024-11-23T14:47:26.699153Z","shell.execute_reply":"2024-11-23T14:47:26.946955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Комбинирование тренировочных и текстовых данных для двух доменов\ntrain = pd.concat([train_zvuk, train_smm], ignore_index=True)\ntest = pd.concat([test_zvuk, test_smm], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:26.948798Z","iopub.execute_input":"2024-11-23T14:47:26.949167Z","iopub.status.idle":"2024-11-23T14:47:29.360907Z","shell.execute_reply.started":"2024-11-23T14:47:26.949130Z","shell.execute_reply":"2024-11-23T14:47:29.360217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Препроцессинг\ntrain, test = preprocess_data(train, test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:47:29.362240Z","iopub.execute_input":"2024-11-23T14:47:29.362766Z","iopub.status.idle":"2024-11-23T14:48:28.975137Z","shell.execute_reply.started":"2024-11-23T14:47:29.362724Z","shell.execute_reply":"2024-11-23T14:48:28.974406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Кодирование user_id\nuser_encoder = LabelEncoder()\ntrain['user_id_enc'] = user_encoder.fit_transform(train['user_id'])\ntest['user_id_enc'] = user_encoder.transform(test['user_id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:48:28.976124Z","iopub.execute_input":"2024-11-23T14:48:28.976391Z","iopub.status.idle":"2024-11-23T14:48:46.135847Z","shell.execute_reply.started":"2024-11-23T14:48:28.976365Z","shell.execute_reply":"2024-11-23T14:48:46.135131Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Кодирование item_id\nitem_encoder = LabelEncoder()\ntrain['item_id_enc'] = item_encoder.fit_transform(train['item_id'])\ntest['item_id_enc'] = item_encoder.transform(test['item_id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:48:46.136935Z","iopub.execute_input":"2024-11-23T14:48:46.137223Z","iopub.status.idle":"2024-11-23T14:49:04.023719Z","shell.execute_reply.started":"2024-11-23T14:48:46.137196Z","shell.execute_reply":"2024-11-23T14:49:04.022991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучение модели ALS\nprint(\"Обучение модели ALS...\")\nals_model = generate_candidates_als(train[['user_id_enc', 'item_id_enc', 'rating']], user_encoder, item_encoder)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:49:04.024656Z","iopub.execute_input":"2024-11-23T14:49:04.024911Z","iopub.status.idle":"2024-11-23T14:52:29.794768Z","shell.execute_reply.started":"2024-11-23T14:49:04.024885Z","shell.execute_reply":"2024-11-23T14:52:29.793748Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Сохранение модели ALS\nals_model_path = os.path.join(MODEL_PATH, 'als_model_combined.pkl')\nwith open(als_model_path, 'wb') as f:\n    pickle.dump(als_model, f)\nprint(f\"Модель ALS сохранена в {als_model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:52:29.795949Z","iopub.execute_input":"2024-11-23T14:52:29.796246Z","iopub.status.idle":"2024-11-23T14:52:30.053432Z","shell.execute_reply.started":"2024-11-23T14:52:29.796219Z","shell.execute_reply":"2024-11-23T14:52:30.052528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Подготовка последовательностей для BERT4Rec\ntrain_sequences = train.sort_values('datetime').groupby('user_id_enc')['item_id_enc'].apply(list).values\nitem_num = train['item_id_enc'].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:52:30.054389Z","iopub.execute_input":"2024-11-23T14:52:30.054622Z","iopub.status.idle":"2024-11-23T14:52:54.402451Z","shell.execute_reply.started":"2024-11-23T14:52:30.054599Z","shell.execute_reply":"2024-11-23T14:52:54.401667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучение модели BERT4Rec\nprint(\"Обучение модели BERT4Rec...\")\nbert_model, special_tokens = train_bert4rec(train_sequences, item_num)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:52:54.403473Z","iopub.execute_input":"2024-11-23T14:52:54.403751Z","iopub.status.idle":"2024-11-23T16:06:43.660614Z","shell.execute_reply.started":"2024-11-23T14:52:54.403723Z","shell.execute_reply":"2024-11-23T16:06:43.659617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Сохранение модели BERT4Rec\nbert_model_path = os.path.join(MODEL_PATH, 'bert_model_combined.pth')\ntorch.save(bert_model.state_dict(), bert_model_path)\nprint(f\"Модель BERT4Rec сохранена в {bert_model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:06:43.661956Z","iopub.execute_input":"2024-11-23T16:06:43.662854Z","iopub.status.idle":"2024-11-23T16:06:44.269405Z","shell.execute_reply.started":"2024-11-23T16:06:43.662811Z","shell.execute_reply":"2024-11-23T16:06:44.268496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Генерация признаков\n# Признаки пользователей\nuser_features = train.groupby('user_id').agg({\n    'rating': ['mean', 'count'],\n    'day_of_week': lambda x: x.mode()[0],\n    'hour_of_day': lambda x: x.mode()[0]\n}).reset_index()\nuser_features.columns = ['user_id', 'user_rating_mean', 'user_rating_count', 'user_day_of_week_mode', 'user_hour_of_day_mode']\n\n# Признаки айтемов\nitem_features = train.groupby(['item_id', 'domain']).agg({\n    'rating': ['mean', 'count'],\n    'day_of_week': lambda x: x.mode()[0],\n    'hour_of_day': lambda x: x.mode()[0]\n}).reset_index()\nitem_features.columns = ['item_id', 'domain', 'item_rating_mean', 'item_rating_count', 'item_day_of_week_mode', 'item_hour_of_day_mode']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:16:23.799647Z","iopub.execute_input":"2024-11-23T16:16:23.799981Z","iopub.status.idle":"2024-11-23T16:18:42.209372Z","shell.execute_reply.started":"2024-11-23T16:16:23.799950Z","shell.execute_reply":"2024-11-23T16:18:42.208610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучение ранжирующей модели CatBoost\nprint(\"Обучение модели CatBoost...\")\ncatboost_model = train_ranking_model(train, user_features, item_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T16:26:39.736046Z","iopub.execute_input":"2024-11-23T16:26:39.736689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Сохранение модели CatBoost\ncatboost_model_path = os.path.join(MODEL_PATH, 'catboost_model_combined.cbm')\ncatboost_model.save_model(catboost_model_path)\nprint(f\"Модель CatBoost сохранена в {catboost_model_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T08:43:53.560017Z","iopub.status.idle":"2024-11-23T08:43:53.560316Z","shell.execute_reply.started":"2024-11-23T08:43:53.560170Z","shell.execute_reply":"2024-11-23T08:43:53.560184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Генерация рекомендаций для каждого домена\nfor domain in ['zvuk', 'smm']:\n    print(f\"Генерация рекомендаций для {domain}...\")\n    \n    # Фильтр для тестовых пользователей из домена\n    test_domain = test[test['domain'] == domain]\n    test_user_ids = test_domain['user_id'].unique()\n    \n    # Генерация 50*K кандидатов для каждого пользователя\n    candidates = []\n    user_item_matrix = csr_matrix(\n        (train['rating'], (train['user_id_enc'], train['item_id_enc']))\n    )\n    for user in tqdm(test_domain['user_id_enc'].unique(), desc=f\"Генерация кандидатов для {domain}\"):\n        user_items = train[train['user_id_enc'] == user]['item_id_enc'].values\n        recs = als_model.recommend(user, user_item_matrix.T.tocsr(), N=K * 50, filter_already_liked_items=True)\n        candidates.extend([(user, item) for item in recs[0]])\n    \n    candidate_df = pd.DataFrame(candidates, columns=['user_id_enc', 'item_id_enc'])\n    candidate_df = candidate_df.drop_duplicates()\n    candidate_df['user_id'] = user_encoder.inverse_transform(candidate_df['user_id_enc'])\n    candidate_df['item_id'] = item_encoder.inverse_transform(candidate_df['item_id_enc'])\n    \n    # Добавление информации о домене к кандидатам\n    candidate_df = candidate_df.merge(item_features[['item_id', 'domain']], on='item_id', how='left')\n    \n    # Фильтр кандидатов для текущего домена\n    candidate_df = candidate_df[candidate_df['domain'] == domain]\n    \n    # Объединение признаков\n    candidate_df = candidate_df.merge(user_features, on='user_id', how='left').merge(\n        item_features, on=['item_id', 'domain'], how='left')\n    \n    # Подготовка данных для предсказаний\n    X_candidate = candidate_df.drop(['user_id', 'item_id', 'user_id_enc', 'item_id_enc', 'domain'], axis=1)\n    \n    # Для правильного кодирования категориальных признаков\n    X_candidate['day_of_week'] = X_candidate['item_day_of_week_mode'].astype(str)\n    X_candidate['hour_of_day'] = X_candidate['item_hour_of_day_mode'].astype(str)\n    X_candidate['domain'] = domain\n    \n    X_candidate = X_candidate.drop(['item_day_of_week_mode', 'item_hour_of_day_mode', 'user_day_of_week_mode', 'user_hour_of_day_mode'], axis=1)\n    \n    # Предсказание скоров\n    candidate_df['score'] = catboost_model.predict(X_candidate)\n    \n    # Генерация рекомендаций\n    recommendations = candidate_df.groupby('user_id').apply(\n        lambda x: x.sort_values('score', ascending=False)['item_id'].tolist()[:K]\n    ).reset_index()\n    recommendations.columns = ['user_id', 'item_ids']\n    \n    # Сохранение результатов\n    submission_file = f'submission_{domain}.parquet'\n    recommendations.to_parquet(os.path.join(DATA_PATH, submission_file), index=False)\n    print(f\"Рекомендации для {domain} Сохранены в {submission_file}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T08:43:53.561649Z","iopub.status.idle":"2024-11-23T08:43:53.561927Z","shell.execute_reply.started":"2024-11-23T08:43:53.561794Z","shell.execute_reply":"2024-11-23T08:43:53.561809Z"}},"outputs":[],"execution_count":null}]}